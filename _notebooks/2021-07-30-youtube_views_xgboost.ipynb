{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-65mH4BkmdS"
   },
   "source": [
    "# YouTube Views with XGBoost\n",
    "> Predicting views using XGBoost and data from YouTube and Google APIs \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![kaggle_img000](https://github.com/jmmerrell/ws/blob/master/images/youtube.jpg?raw=true)\n",
    "\n",
    "I wanted to find the features that help me get more views on YouTube. Successfully identified which YouTube videos are successful with 85% accuracy. I used the YouTube API to gather data from my competitors on YouTube. I also used Google Vision's deep learning models to analyzye thumbnail images, and add that data to the YouTube API data. Data from nearly 2,000 videos was used to train and test an XGBoost model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- toc: true\n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [XGBoost,YouTube,API,Google Vision]\n",
    "- image: images/youtube.jpg\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Ime_gOak4Fe"
   },
   "source": [
    "## 1. Objective\n",
    "\n",
    "We want to classify videos as succesful(high views per subscriber) or unsuccessful by scraping data from YouTube and using the data to train an XGBoost model. The main sources of data for this project are the APIs for YouTube and GoogleVision. From these two sources we gather information about each of my competitor's YouTube channels: views, subscribers, number of videos, titles of the videos, duration of each video, etc. From the YouTube API I also extract the thubnail URL for each video. Later I explain how the Google Vision API analyzes the image of the thumbnail for facial and text recognition. I combine the youtube data and the thumbnail data together for the analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hD8003ddw-S_"
   },
   "source": [
    "## 2. Import the necessary libraries and data set\n",
    "\n",
    "### 2.1. Libraries\n",
    "\n",
    "The libraries used in this project are the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "o5EGiQqIw5mn"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"C:\\\\Users\\\\merre\\\\Desktop\\\\envs\\\\yt_api_env\\\\Lib\\\\site-packages\")\n",
    "from numpy.core.fromnumeric import shape\n",
    "from numpy.lib.function_base import diff\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.core.indexes.base import Index\n",
    "import emoji\n",
    "from scipy import stats\n",
    "import fasttext\n",
    "from collections import Counter\n",
    "from pprint import pprint \n",
    "from IPython.display import display_html\n",
    "from itertools import chain,cycle\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "import matplotlib.pylab as pl\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QmelGdnyBF0"
   },
   "source": [
    "### 2.2. Data Sets\n",
    "\n",
    "I merge together all the datasets taken from YouTube's API with the Google Vision API thumbnail image data. You can see the full code below for retreiving this data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTube API Data Pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "\n",
    "import json\n",
    "import requests\n",
    "from numpy import random\n",
    "from time import sleep\n",
    "import os\n",
    "\n",
    "class YTstats:\n",
    "\n",
    "    def __init__(self, api_key, channel_id):\n",
    "        self.api_key = api_key\n",
    "        self.channel_id = channel_id\n",
    "        self.channel_statistics = None\n",
    "        self.video_data = None\n",
    "\n",
    "    def extract_all(self):\n",
    "        self.get_channel_statistics()\n",
    "        self.get_channel_video_data()\n",
    "\n",
    "    def get_channel_statistics(self):\n",
    "        \"\"\"Extract the channel statistics\"\"\"\n",
    "        print('get channel statistics...')\n",
    "        url = f'https://www.googleapis.com/youtube/v3/channels?part=statistics&id={self.channel_id}&key={self.api_key}'\n",
    "        \n",
    "        json_url = requests.get(url)\n",
    "        data = json.loads(json_url.text)\n",
    "        try:\n",
    "            data = data['items'][0]['statistics']\n",
    "        except KeyError:\n",
    "            print('Could not get channel statistics')\n",
    "            data = {}\n",
    "\n",
    "        self.channel_statistics = data\n",
    "        return data\n",
    "\n",
    "    def get_channel_video_data(self):\n",
    "        global s\n",
    "        s = requests.Session()\n",
    "        \"Extract all video information of the channel\"\n",
    "        print('get video data...')\n",
    "        channel_videos, channel_playlists = self._get_channel_content(limit=50)\n",
    "\n",
    "        parts=[\"snippet\", \"statistics\",\"contentDetails\", \"topicDetails\"]\n",
    "        print(len(channel_videos))\n",
    "        ii = 0\n",
    "       \n",
    "        for video_id in channel_videos:\n",
    "            ii += 1\n",
    "            print(ii/len(channel_videos))\n",
    "            for part in parts:\n",
    "                data = self._get_single_video_data(video_id, part)\n",
    "                channel_videos[video_id].update(data)\n",
    "\n",
    "\n",
    "        self.video_data = channel_videos\n",
    "        return channel_videos\n",
    "\n",
    "    def _get_single_video_data(self, video_id, part):\n",
    "        \"\"\"\n",
    "        Extract further information for a single video\n",
    "        parts can be: 'snippet', 'statistics', 'contentDetails', 'topicDetails'\n",
    "        \"\"\"\n",
    "        sleep(random.uniform(1, 3)/2)\n",
    "        url = f\"https://www.googleapis.com/youtube/v3/videos?part={part}&id={video_id}&key={self.api_key}\"\n",
    "        json_url = s.get(url)\n",
    "        data = json.loads(json_url.text)\n",
    "        print(url)\n",
    "    \n",
    "        try:\n",
    "            data = data['items'][0][part]\n",
    "        except KeyError as e:\n",
    "            print(f'Error! Could not get {part} part of data: \\n{data}')\n",
    "            data = dict()\n",
    "        return data\n",
    "\n",
    "    def _get_channel_content(self, limit=None, check_all_pages=True):\n",
    "        \"\"\"\n",
    "        Extract all videos and playlists, can check all available search pages\n",
    "        channel_videos = videoId: title, publishedAt\n",
    "        channel_playlists = playlistId: title, publishedAt\n",
    "        return channel_videos, channel_playlists\n",
    "        \"\"\"\n",
    "        url = f\"https://www.googleapis.com/youtube/v3/search?key={self.api_key}&channelId={self.channel_id}&part=snippet,id&order=date\"\n",
    "        if limit is not None and isinstance(limit, int):\n",
    "            url += \"&maxResults=\" + str(limit)\n",
    "\n",
    "        vid, pl, npt = self._get_channel_content_per_page(url)\n",
    "        idx = 0\n",
    "        \n",
    "        while(check_all_pages and npt is not None and idx < 50 and num_pages < 2):\n",
    "            nexturl = url + \"&pageToken=\" + npt\n",
    "            next_vid, next_pl, npt = self._get_channel_content_per_page(nexturl)\n",
    "            vid.update(next_vid)\n",
    "            pl.update(next_pl)\n",
    "            idx += 1\n",
    "            print(check_all_pages, idx, npt)\n",
    "\n",
    "        return vid, pl\n",
    "\n",
    "    def _get_channel_content_per_page(self, url):\n",
    "        \"\"\"\n",
    "        Extract all videos and playlists per page\n",
    "        return channel_videos, channel_playlists, nextPageToken\n",
    "        \"\"\"\n",
    "        sleep(random.uniform(1, 3))\n",
    "        json_url = requests.get(url)\n",
    "        data = json.loads(json_url.text)\n",
    "        channel_videos = dict()\n",
    "        channel_playlists = dict()\n",
    "        if 'items' not in data:\n",
    "            print('Error! Could not get correct channel data!\\n', data)\n",
    "            return channel_videos, channel_playlists, None\n",
    "        global num_pages\n",
    "        num_pages+=1\n",
    "        nextPageToken = data.get(\"nextPageToken\", None)\n",
    "\n",
    "        item_data = data['items']\n",
    "        for item in item_data:\n",
    "            try:\n",
    "                kind = item['id']['kind']\n",
    "                published_at = item['snippet']['publishedAt']\n",
    "                title = item['snippet']['title']\n",
    "                if kind == 'youtube#video':\n",
    "                    video_id = item['id']['videoId']\n",
    "                    channel_videos[video_id] = {'publishedAt': published_at, 'title': title}\n",
    "                elif kind == 'youtube#playlist':\n",
    "                    playlist_id = item['id']['playlistId']\n",
    "                    channel_playlists[playlist_id] = {'publishedAt': published_at, 'title': title}\n",
    "            except KeyError as e:\n",
    "                print('Error! Could not extract data from item:\\n', item)\n",
    "\n",
    "        return channel_videos, channel_playlists, nextPageToken\n",
    "\n",
    "    def dump(self):\n",
    "        \"\"\"Dumps channel statistics and video data in a single json file\"\"\"\n",
    "        if self.channel_statistics is None or self.video_data is None:\n",
    "            print('data is missing!\\nCall get_channel_statistics() and get_channel_video_data() first!')\n",
    "            return\n",
    "\n",
    "        fused_data = {self.channel_id: {\"channel_statistics\": self.channel_statistics,\n",
    "                              \"video_data\": self.video_data}}\n",
    "\n",
    "        channel_title = self.video_data.popitem()[1].get('channelTitle', self.channel_id)\n",
    "        channel_title = channel_title.replace(\" \", \"_\").lower()\n",
    "        filename = channel_title + '.json'\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(fused_data, f, indent=4)\n",
    "        \n",
    "        print('file dumped to', filename)\n",
    "\n",
    "\n",
    "#brian hull UCiNeUoUWfBLC8mJuMzI6hvw\n",
    "#Black Gryphon UCvzWGXYFDiiJ338KIJPhbhQ \n",
    "#Brock Baker  UCLzdMXE3R2xXIklfIO9HCcQ\n",
    "# Ori  UCra3g9Qvmgux0NyY2Pdj4Lw\n",
    "# Scheiffer Bates   UCcBacTJIf67LSU_-yeJwDvg\n",
    "#Azerrz  UCiwIAU4SNlrcv47504JrJeQ\n",
    "#Danny padilla & mason sperling  UCfhK8MfxO-9RCypkLDyW1rw\n",
    "# Brizzy UC7lObFRyZgoZcMYHHqxi9lg\n",
    "# Redfireball UC88CnZTYFz5ugp-JtDEQ3-g\n",
    "# Sounds like pizza  UCh6OfzCefcCGFfihPbe_Y4g\n",
    "#joshiiwuh  UCxRGk49YNiW3Cq8s7MGknqw\n",
    "# simau UCkXvCWJjAqNcFwxF7hW_ZRQ\n",
    "#Knep UCy7gv-FM-dMvw6dMtj8Qfgg\n",
    "# charlie hopkinson  UCewLMcro9tNP97XQ1rxtLXQ\n",
    "#Uss JA doin  UCqPYUMNbVeEhyTBIZCDO_VQ\n",
    "# Shanieology  UCR93YdwZ4UKEUwf1gA-ZusA\n",
    "# BigShade  UC7Wt6Nukmt83Bph3us5s5Aw\n",
    "# Best in Class  UClQhFMEVUxJAwMW-KdZ0SvQ\n",
    "# Daniel Ferguson  UCXFzOJmXVaP1tMLiww4aQzg\n",
    "# Mikey Boltz  UC0gXT2T6KtmV0IHNNNvruAQ\n",
    "# Maxamili  UC-0WjH-efG2qvNlZUBlX70Q\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "api_key= os.environ.get('YT_API')\n",
    "\n",
    "# channel_ids= ['UCiNeUoUWfBLC8mJuMzI6hvw','UCvzWGXYFDiiJ338KIJPhbhQ','UCLzdMXE3R2xXIklfIO9HCcQ','UCra3g9Qvmgux0NyY2Pdj4Lw','UCcBacTJIf67LSU_-yeJwDvg',\n",
    "# 'UCiwIAU4SNlrcv47504JrJeQ','UCfhK8MfxO-9RCypkLDyW1rw','UC7lObFRyZgoZcMYHHqxi9lg','UC88CnZTYFz5ugp-JtDEQ3-g','UCh6OfzCefcCGFfihPbe_Y4g',\n",
    "# 'UCxRGk49YNiW3Cq8s7MGknqw','UCkXvCWJjAqNcFwxF7hW_ZRQ','UCy7gv-FM-dMvw6dMtj8Qfgg','UCewLMcro9tNP97XQ1rxtLXQ','UCqPYUMNbVeEhyTBIZCDO_VQ',\n",
    "# 'UCR93YdwZ4UKEUwf1gA-ZusA','UC7Wt6Nukmt83Bph3us5s5Aw','UClQhFMEVUxJAwMW-KdZ0SvQ','UCXFzOJmXVaP1tMLiww4aQzg','UC0gXT2T6KtmV0IHNNNvruAQ',\n",
    "# 'UC-0WjH-efG2qvNlZUBlX70Q']\n",
    "\n",
    "channel_ids= ['UC-0WjH-efG2qvNlZUBlX70Q','UClQhFMEVUxJAwMW-KdZ0SvQ']\n",
    "\n",
    "for channel_id in channel_ids:\n",
    "    global num_pages\n",
    "    num_pages = 0\n",
    "    yt = YTstats(api_key,channel_id)\n",
    "    yt.get_channel_statistics()\n",
    "    yt.get_channel_video_data()\n",
    "    yt.dump()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Convert JSON to Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "\n",
    "import json\n",
    "from os import replace\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import cv2\n",
    "import urllib\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#C:/Users/merre/Desktop/data projects/\n",
    "files= [\"shanieology.json\",\"simau.json\",\"soundslikepizza.json\",\"azerrz.json\",\"BigShade.json\",\"black_gryph0n.json\"\n",
    ",\"brian_hull.json\",\"brizzy_voices.json\",\"brock_baker.json\",\"charlie_hopkinson.json\",\"danny_padilla_&_mason_sperling.json\"\n",
    ",\"ja_doin_stuff.json\",\"joshiiwuh.json\",\"knep.json\",\"ori.json\",\"redfireball555.json\",\"scheiffer_bates.json\",\"daniel_ferguson.json\",\n",
    "\"BigShade.json\",\"best_in_class.json\",\"maxamili.json\",\"mikey_bolts.json\"]\n",
    "\n",
    "data=None\n",
    "df_channel_new=None\n",
    "df_channel = None\n",
    "\n",
    "for file in files:\n",
    "    with open(file,'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    channel_id, stats = data.popitem()\n",
    "    channel_stats=stats[\"channel_statistics\"]\n",
    "    video_stats = stats[\"video_data\"]\n",
    "    channel_views= channel_stats[\"viewCount\"]\n",
    "    channel_subs= channel_stats[\"subscriberCount\"]\n",
    "    channel_videos= channel_stats[\"videoCount\"]\n",
    "    try:\n",
    "        sorted_vids = sorted(video_stats.items(), key=lambda item: int(item[1][\"viewCount\"]), reverse=True)\n",
    "    except:\n",
    "        sorted_vids = video_stats.items()\n",
    "    stats = []\n",
    "    for vid in sorted_vids:\n",
    "        video_id = vid[0]\n",
    "        title = vid[1][\"title\"]\n",
    "        title_len = len(title)\n",
    "        title_words = re.findall(r'\\w+',title)\n",
    "        words=0\n",
    "        upper_words=0\n",
    "        for word in title_words:\n",
    "            words += 1\n",
    "            if word.isupper():\n",
    "                upper_words += 1\n",
    "        upper_pct = upper_words/words\n",
    "        \n",
    "        emoji_count = len(re.findall(u'[\\U0001f600-\\U0001f650]', title))\n",
    "        \n",
    "        #Convert time to Mexico City Time\n",
    "        upload_date_time = datetime.strptime(vid[1][\"publishedAt\"],'%Y-%m-%dT%H:%M:%SZ')-timedelta(hours=5)\n",
    "        upload_date = upload_date_time.date()\n",
    "        upload_time = upload_date_time.time()\n",
    "        #0 is Monday, 6 is Sunday\n",
    "        upload_day = upload_date.weekday()\n",
    "        if datetime.strptime('04:00:00', '%H:%M:%S').time() <= upload_time <= datetime.strptime('10:30:00', '%H:%M:%S').time():\n",
    "            upload_time_of_day = 'morning'\n",
    "        elif datetime.strptime('10:30:01', '%H:%M:%S').time() <= upload_time <= datetime.strptime('18:00:00', '%H:%M:%S').time():\n",
    "            upload_time_of_day = 'afternoon'\n",
    "        elif datetime.strptime('18:00:01', '%H:%M:%S').time() <= upload_time <= datetime.strptime('23:00:00', '%H:%M:%S').time():\n",
    "            upload_time_of_day = 'night'\n",
    "        else:\n",
    "            upload_time_of_day = \"late_night\"\n",
    "        try:\n",
    "            thumbnail_url = vid[1][\"thumbnails\"][\"maxres\"][\"url\"]\n",
    "            thumbnail_h = vid[1][\"thumbnails\"][\"maxres\"][\"height\"]\n",
    "            thumbnail_w = vid[1][\"thumbnails\"][\"maxres\"][\"width\"]\n",
    "        except:\n",
    "            try:\n",
    "                thumbnail_url = vid[1][\"thumbnails\"][\"high\"][\"url\"]\n",
    "                thumbnail_h = vid[1][\"thumbnails\"][\"high\"][\"height\"]\n",
    "                thumbnail_w = vid[1][\"thumbnails\"][\"high\"][\"width\"]\n",
    "            except:\n",
    "                try:\n",
    "                    thumbnail_url = vid[1][\"thumbnails\"][\"default\"][\"url\"]\n",
    "                    thumbnail_h = vid[1][\"thumbnails\"][\"default\"][\"height\"]\n",
    "                    thumbnail_w = vid[1][\"thumbnails\"][\"default\"][\"width\"]  \n",
    "                except:\n",
    "                    thumbnail_url=None\n",
    "                    thumbnail_h=None\n",
    "                    thumbnail_w=None                  \n",
    "        try:\n",
    "            channel = vid[1][\"channelTitle\"]\n",
    "        except:\n",
    "            channel=None\n",
    "        try:\n",
    "            tags = vid[1][\"tags\"]\n",
    "        except:\n",
    "            tag = None\n",
    "        num_tags = len(tags)\n",
    "        try:\n",
    "            categoryId = vid[1][\"categoryId\"]\n",
    "        except:\n",
    "            categoryId=None\n",
    "        try: \n",
    "            liveBroadcastContent = vid[1][\"liveBroadcastContent\"]\n",
    "        except:\n",
    "            liveBroadcastContent = None\n",
    "        try:\n",
    "            defaultAudioLanguage = vid[1][\"defaultAudioLanguage\"]\n",
    "        except:\n",
    "            defaultAudioLanguage = None\n",
    "        try:\n",
    "            viewCount = vid[1][\"viewCount\"]\n",
    "        except:\n",
    "            viewCount = None\n",
    "        try:\n",
    "            likeCount = vid[1][\"likeCount\"]\n",
    "        except:\n",
    "            likeCount =None\n",
    "        try:\n",
    "            dislikeCount = vid[1][\"dislikeCount\"]\n",
    "        except:\n",
    "            dislikeCount=None\n",
    "        try:\n",
    "            favoriteCount = vid[1][\"favoriteCount\"]\n",
    "        except:\n",
    "            favoriteCount = None\n",
    "        try:\n",
    "            commentCount = vid[1][\"commentCount\"]\n",
    "        except:\n",
    "            commentCount=None\n",
    "        \n",
    "        try:\n",
    "            duration0 = vid[1][\"duration\"]\n",
    "        except:\n",
    "            duration0=None\n",
    "        try:\n",
    "            hours = int(re.findall(r'\\d+H',duration0)[0].replace('H',''))\n",
    "        except:\n",
    "            hours = None\n",
    "        try:\n",
    "            mins = int(re.findall(r'\\d+M',duration0)[0].replace('M',''))\n",
    "        except:\n",
    "            mins=None\n",
    "        try:\n",
    "            secs = int(re.findall(r'\\d+S',duration0)[0].replace('S',''))\n",
    "        except:\n",
    "            secs=0\n",
    "        if hours is not None and mins is not None and secs is not None:\n",
    "            duration = hours*60 + mins + secs/60\n",
    "        elif mins is not None and secs is not None:\n",
    "            duration = mins + secs/60\n",
    "        elif secs is not None:\n",
    "            duration = secs/60\n",
    "\n",
    "        try:\n",
    "            definition = vid[1][\"definition\"]\n",
    "        except:\n",
    "            definition =None\n",
    "        try:\n",
    "            captions = vid[1][\"caption\"]\n",
    "        except:\n",
    "            captions = None\n",
    "        try:    \n",
    "            licensedContent = vid[1][\"licensedContent\"]\n",
    "        except:\n",
    "            licensedContent=None\n",
    "        try:\n",
    "            projection = vid[1][\"projection\"]\n",
    "        except:\n",
    "            projection = None\n",
    "        try:\n",
    "            topicCategories = vid[1][\"topicCategories\"]\n",
    "        except:\n",
    "            topicCategories = None\n",
    "        try:\n",
    "            desc = vid[1][\"description\"]\n",
    "        except:\n",
    "            desc = None\n",
    "\n",
    "        video_id = vid[0]\n",
    "        stats.append([video_id,title,title_len,words,upper_pct,emoji_count,upload_date,upload_time,upload_day,upload_time_of_day,viewCount,likeCount,dislikeCount,favoriteCount,\n",
    "        commentCount,duration,definition,captions,licensedContent,thumbnail_url, thumbnail_w, thumbnail_h, tags,num_tags,categoryId,liveBroadcastContent,\n",
    "        defaultAudioLanguage,topicCategories, channel, channel_subs, channel_views, channel_videos,desc])\n",
    "    df = pd.DataFrame(stats)\n",
    "    df.columns = ['video_id','title','title_len','words','upper_pct','emoji_count','upload_date','upload_time','upload_day','upload_time_of_day','viewCount','likeCount','dislikeCount',\n",
    "    'favoriteCount','commentCount','duration','definition','caption','licensedContent','thumbnail_url', 'thumbnail_w', 'thumbnail_h', 'tags','num_tags',\n",
    "    'categoryId','liveBroadcastContent','defaultAudioLanguage','topicCategories', 'channel', 'channel_subs', 'channel_views', 'channel_videos','desc']\n",
    "    df.to_csv(file.replace('json','txt'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Functions to Query Google Vision API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "\n",
    "import httplib2\n",
    "import sys\n",
    "from googleapiclient import discovery\n",
    "from oauth2client import tools, file, client\n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "from base64 import b64encode\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# limited preview only (sorry!) \n",
    "API_DISCOVERY_FILE = os.environ.get('GOOGLE_VISION_API')\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" Google Authentication Utilities \"\"\"\n",
    "\n",
    "def get_vision_api():\n",
    "\tcredentials = get_api_credentials('https://www.googleapis.com/auth/cloud-platform')\n",
    "\twith open(API_DISCOVERY_FILE, 'r') as f:\n",
    "\t\tdoc = f.read()\t\n",
    "\treturn discovery.build_from_document(doc, credentials=credentials, http=httplib2.Http())\n",
    "\n",
    "\n",
    "def get_api_credentials(scope, service_account=True):\n",
    "\t\"\"\" Build API client based on oAuth2 authentication \"\"\"\n",
    "\t# STORAGE = file.Storage(os.environ.get('GOOGLE_VISION_API')) #local storage of oAuth tokens\n",
    "\tSTORAGE = file.Storage(API_DISCOVERY_FILE) #local storage of oAuth tokens\n",
    "\tcredentials = STORAGE.get()\n",
    "\tif credentials is None or credentials.invalid: #check if new oAuth flow is needed\n",
    "\t\tif service_account: #server 2 server flow\n",
    "\t\t\t# with open(os.environ.get('GOOGLE_VISION_API')) as f:\n",
    "\t\t\twith open(API_DISCOVERY_FILE) as f:\n",
    "\t\t\t\taccount = json.loads(f.read())\n",
    "\t\t\t\temail = account['client_email']\n",
    "\t\t\t\tkey = account['private_key']\n",
    "\t\t\tcredentials = client.SignedJwtAssertionCredentials(email, key, scope=scope)\n",
    "\t\t\tSTORAGE.put(credentials)\n",
    "\t\telse: #normal oAuth2 flow\n",
    "\t\t\tCLIENT_SECRETS = os.path.join(os.path.dirname(__file__), 'client_secrets.json')\n",
    "\t\t\tFLOW = client.flow_from_clientsecrets(CLIENT_SECRETS, scope=scope)\n",
    "\t\t\tPARSER = argparse.ArgumentParser(description=__doc__, formatter_class=argparse.RawDescriptionHelpFormatter, parents=[tools.argparser])\n",
    "\t\t\tFLAGS = PARSER.parse_args(sys.argv[1:])\n",
    "\t\t\tcredentials = tools.run_flow(FLOW, STORAGE, FLAGS)\n",
    "\t\t\n",
    "\treturn credentials\n",
    "\n",
    "\n",
    "\"\"\" read/write utilities \"\"\"\n",
    "\n",
    "def read_image(filename):\n",
    "\treturn cv2.imread(filename)\n",
    "\n",
    "def save_image(filename, im):\n",
    "\tcv2.imwrite(filename, cv2.cvtColor(im, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "def read_image_base64(filename):\n",
    "\twith open(filename, 'rb') as f:\n",
    "\t\treturn b64encode(f.read())\n",
    "\n",
    "\n",
    "\"\"\" OpenCV drawing utilities \"\"\"\n",
    "\n",
    "def draw_face(im, annotations):\n",
    "\tfaces = []\n",
    "\tfor a in annotations:\n",
    "\t\tif a['detectionConfidence'] > .4:\n",
    "\t\t\ttry:\n",
    "\t\t\t\ttl_,br_ = draw_box(im, a['fdBoundingPoly']['vertices'])\n",
    "\t\t\texcept:\n",
    "\t\t\t\ttl_,br_=None\n",
    "\n",
    "\t\t\ttry:\n",
    "\t\t\t\tjoy = a['joyLikelihood']\n",
    "\t\t\texcept:\n",
    "\t\t\t\tjoy=''\n",
    "\t\t\ttry:\n",
    "\t\t\t\tsad = a['sorrowLikelihood']\n",
    "\t\t\texcept:\n",
    "\t\t\t\tsad=''\n",
    "\t\t\ttry:\n",
    "\t\t\t\tangry = a['angerLikelihood']\n",
    "\t\t\texcept:\n",
    "\t\t\t\tangry = ''\n",
    "\t\t\ttry:\n",
    "\t\t\t\tsuprise=a['surpriseLikelihood']\n",
    "\t\t\texcept:\n",
    "\t\t\t\tsuprise=''\n",
    "\n",
    "\t\t\temotions=[joy,sad,angry,suprise]\n",
    "\n",
    "\t\t\tif 'VERY_LIKELY' in emotions:\n",
    "\t\t\t\temotion = emotions.index('VERY_LIKELY')\n",
    "\t\t\telif 'LIKELY' in emotions:\n",
    "\t\t\t\temotion = emotions.index('LIKELY')\n",
    "\t\t\telif 'POSSIBLE' in emotions:\n",
    "\t\t\t\temotion = emotions.index('POSSIBLE')\n",
    "\t\t\telse:\n",
    "\t\t\t\temotion=None\n",
    "\t\t\t\n",
    "\t\t\tif emotion==0:\n",
    "\t\t\t\ttext= \"happy\"\n",
    "\t\t\telif emotion==1:\n",
    "\t\t\t\ttext=\"sad\"\n",
    "\t\t\telif emotion==2:\n",
    "\t\t\t\ttext=\"angry\"\n",
    "\t\t\telif emotion==3:\n",
    "\t\t\t\ttext=\"suprised\"\n",
    "\t\t\telse:\n",
    "\t\t\t\ttext=\"other\"\n",
    "\t\t\tfaces.append(text)\n",
    "\t\t\tif im is not None and tl_ is not None:\n",
    "\t\t\t\tdraw_text(im, text ,tl_)\n",
    "\t\t\ttry:\n",
    "\t\t\t\tfor landmark in a['landmarks']:\n",
    "\t\t\t\t\tif im is not None:\n",
    "\t\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\t\tdraw_point(im, landmark['position'])\n",
    "\t\t\t\t\t\texcept:\n",
    "\t\t\t\t\t\t\tpass\n",
    "\t\t\texcept:\n",
    "\t\t\t\tpass\n",
    "\treturn faces\t\n",
    "\n",
    "\n",
    "def extract_vertices(vertices):\n",
    "\t\"\"\" Extract two opposite vertices from a list of 4 (assumption: rectangle) \"\"\"\n",
    "\n",
    "\tmin_x,max_x,min_y,max_y = float(\"inf\"),float(\"-inf\"),float(\"inf\"),float(\"-inf\")\n",
    "\n",
    "\tfor v in vertices:\n",
    "\t\tif v.get('x',min_y) < min_x:\n",
    "\t\t\tmin_x = v.get('x')\n",
    "\t\tif v.get('x',max_y) > max_x:\n",
    "\t\t\tmax_x = v.get('x')\n",
    "\t\tif v.get('y',min_y) < min_y:\n",
    "\t\t\tmin_y = v.get('y')\n",
    "\t\tif v.get('y',max_y) > max_y:\n",
    "\t\t\tmax_y = v.get('y')\n",
    "\ttry:\n",
    "\t\tv1 = next(v for v in vertices if v.get('x') == min_x and v.get('y') == min_y)\n",
    "\t\tv2 = next(v for v in vertices if v.get('x') == max_x and v.get('y') == max_y)\n",
    "\texcept:\n",
    "\t\tv1=None\n",
    "\t\tv2=None\n",
    "\n",
    "\treturn v1,v2\n",
    "\n",
    "\n",
    "def draw_box(im, vertices):\n",
    "\tv1,v2 = extract_vertices(vertices)\n",
    "\ttry:\n",
    "\t\tpt1 = (v1.get('x',0), v1.get('y',0))\n",
    "\t\tpt2 = (v2.get('x',0), v2.get('y',0))\n",
    "\t\tcv2.rectangle(im, pt1, pt2, (0,0,255),thickness=4)\n",
    "\texcept:\n",
    "\t\tpt1=None\n",
    "\t\tpt2=None\n",
    "\treturn pt1, pt2\n",
    "\n",
    "def draw_point(im, position):\n",
    "\tpt = (int(position.get('x',0)), int(position.get('y',0)))\n",
    "\tcv2.circle(im, pt, 3, (0,0,255))\n",
    "\treturn pt\n",
    "\n",
    "def draw_text(im, text,loc):\n",
    "\tfont_face = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\t#thickness = 1\n",
    "\tthickness=round(0.002 * (im.shape[0] + im.shape[1]) / 2) + 10\n",
    "\t# for scale in np.arange(20,0,-0.2):\n",
    "\t# \t(w,h),baseline = cv2.getTextSize(text, font_face, scale, thickness)\n",
    "\t# \tif w <= im.shape[1]:\n",
    "\t# \t\tnew_img = cv2.copyMakeBorder(im, 0, baseline*4, 0, 0, cv2.BORDER_CONSTANT, value=0)\n",
    "\t# \t\tcv2.putText(new_img, text, (baseline*2 +20 ,new_img.shape[0]-baseline +20 ), font_face, 2, (255,255,255), thickness)\n",
    "\t# \t\treturn new_img\n",
    "\tnew_img = im\n",
    "\tcv2.putText(new_img, text, loc, font_face, 2.5, (102,255,0), thickness)\n",
    "\treturn new_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Google Vision API Data Pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "\n",
    "from datetime import date\n",
    "import datetime\n",
    "import json\n",
    "from webbrowser import get\n",
    "from google.cloud.vision_v1.types.image_annotator import AnnotateImageRequest, AnnotateImageResponse\n",
    "from numpy.core.fromnumeric import shape\n",
    "from numpy.core.numeric import NaN\n",
    "from numpy.lib.arraysetops import unique\n",
    "from skimage.util import dtype\n",
    "from functions_for_google_vision_api import (get_vision_api, read_image, read_image_base64, save_image, draw_face, draw_box, draw_text)\n",
    "from skimage import io\n",
    "import os\n",
    "from google.cloud import vision_v1\n",
    "from google.cloud import vision\n",
    "from google.cloud.vision_v1 import types\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import time\n",
    "import random\n",
    "\n",
    "#####################################################################\n",
    "\n",
    "import httplib2\n",
    "from googleapiclient import discovery\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = os.environ.get('GOOGLE_VISION_API')\n",
    "\n",
    "DISCOVERY_URL='https://{api}.googleapis.com/$discovery/rest?version={apiVersion}'\n",
    "\n",
    "def get_vision_service():\n",
    "\tcredentials = GoogleCredentials.get_application_default()\n",
    "\treturn discovery.build('vision', 'v1', credentials=credentials, discoveryServiceUrl = DISCOVERY_URL)\n",
    "\t\n",
    "\n",
    "def main(video_id, inputfile):\n",
    "\tservice = get_vision_service()\n",
    "\toutputfile= \"C:/Users/merre/Desktop/ws/data/youtube_jadoinstuff/output_images/thumbnail_\" +inputfile[inputfile.rfind('/', 0, inputfile.rfind('/'))+1:inputfile.rfind('/')] + \".jpg\"\n",
    "\n",
    "\tbatch_request=[\n",
    "    {\n",
    "      \"features\": [\n",
    "        {\n",
    "          \"maxResults\": 50,\n",
    "          \"type\": \"FACE_DETECTION\"\n",
    "        },\n",
    "        {\n",
    "          \"maxResults\": 50,\n",
    "          \"type\": \"LABEL_DETECTION\"\n",
    "        },\n",
    "        {\n",
    "          \"maxResults\": 20,\n",
    "          \"type\": \"SAFE_SEARCH_DETECTION\"\n",
    "        },\n",
    "        {\n",
    "          \"maxResults\": 50,\n",
    "          \"type\": \"TEXT_DETECTION\"\n",
    "        }\n",
    "      ],\n",
    "\t\t\"image\": {\n",
    "\t\t\t\t\"source\": {\n",
    "\t\t\t\t\"imageUri\": inputfile\n",
    "\t\t\t\t}\n",
    "\t\t\t}\n",
    "    }\n",
    "\t]\n",
    "\trequest = service.images().annotate(body={\n",
    "\t\t'requests': batch_request,\n",
    "\t\t})\n",
    "\ttime.sleep(random.random()*4)\n",
    "\tresponse = request.execute()\n",
    "\tinputfile,labels,faces,texts,adult,medical,racy,spoof,violence = show_results(inputfile, response, outputfile)\n",
    "\tvars_list = [video_id,inputfile,labels,faces,texts,adult,medical,racy,spoof,violence]\n",
    "\ti=0\n",
    "\tfor v in vars_list:\n",
    "\t\tif type(v) == np.ndarray:\n",
    "\t\t\tv = v.tolist()\n",
    "\t\t\tvars_list[i]=v\n",
    "\t\ti += 1\n",
    "\treturn vars_list\n",
    "\n",
    "\n",
    "def show_results(inputfile, data, outputfile):\n",
    "\n",
    "\t#read original file\n",
    "\tim = io.imread(inputfile)\n",
    "\n",
    "\t#draw face, boxes and text for each response\n",
    "\tfaces=[]\n",
    "\tlabels=[]\n",
    "\ttexts=[]\n",
    "\t#dict_keys = data.keys()\n",
    "\tfor r in data['responses']:\n",
    "\t\t\n",
    "\t\tif 'faceAnnotations' in r:\n",
    "\t\t\tfaces = draw_face(im, r['faceAnnotations'])\n",
    "\t\t\n",
    "\t\tif 'labelAnnotations' in r:\n",
    "\t\t\tfor label in r['labelAnnotations']:\n",
    "\t\t\t\tif label['score'] > .6:\n",
    "\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\tlabels.append(label['description'])\n",
    "\t\t\t\t\texcept:\n",
    "\t\t\t\t\t\tlabels=labels\n",
    "\t\t\n",
    "\t\tif 'textAnnotations' in r:\n",
    "\t\t\tfor a in r['textAnnotations']:\n",
    "\t\t\t\tif a['description'] != '':\n",
    "\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\ttexts.append(a['description'])\n",
    "\t\t\t\t\texcept:\n",
    "\t\t\t\t\t\ttexts=texts\n",
    "\t\t\n",
    "\t\tif 'safeSearchAnnotation' in r:\n",
    "\t\t\ttry:\n",
    "\t\t\t\tadult = r['safeSearchAnnotation'][\"adult\"]\n",
    "\t\t\texcept:\n",
    "\t\t\t\tadult=''\n",
    "\t\t\ttry:\n",
    "\t\t\t\tmedical = r['safeSearchAnnotation'][\"medical\"]\n",
    "\t\t\texcept:\n",
    "\t\t\t\tmedical=''\n",
    "\t\t\ttry:\n",
    "\t\t\t\tracy = r['safeSearchAnnotation'][\"racy\"]\n",
    "\t\t\texcept:\n",
    "\t\t\t\tracy=''\n",
    "\t\t\ttry:\t\n",
    "\t\t\t\tspoof = r['safeSearchAnnotation'][\"spoof\"]\n",
    "\t\t\texcept:\n",
    "\t\t\t\tspoof=''\n",
    "\t\t\ttry:\n",
    "\t\t\t\tviolence = r['safeSearchAnnotation'][\"violence\"]\n",
    "\t\t\texcept:\n",
    "\t\t\t\tviolence=''\n",
    "\t\n",
    "\tlabels=unique(labels)\n",
    "\ttexts=unique(texts)\n",
    "\t\t#save to output file\n",
    "\tsave_image(outputfile, im)\n",
    "\n",
    "\treturn inputfile,labels,faces,texts,adult,medical,racy,spoof,violence\n",
    "\n",
    "# files= [\"shanieology.txt\",\"simau.txt\",\"soundslikepizza.txt\",\"azerrz.txt\",\"BigShade.txt\",\"black_gryph0n.txt\"\n",
    "# ,\"brian_hull.txt\",\"brizzy_voices.txt\",\"brock_baker.txt\",\"charlie_hopkinson.txt\",\"danny_padilla_&_mason_sperling.txt\"\n",
    "# ,\"ja_doin_stuff.txt\",\"joshiiwuh.txt\",\"knep.txt\",\"ori.txt\",\"redfireball555.txt\",\"scheiffer_bates.txt\",\"daniel_ferguson.txt\",\n",
    "# \"BigShade.txt\",\"best_in_class.txt\",\"maxamili.txt\",\"mikey_bolts.txt\"]\n",
    "files= [\"daniel_ferguson.txt\",\"BigShade.txt\",\"best_in_class.txt\",\"maxamili.txt\",\"mikey_bolts.txt\"]\n",
    "\n",
    "vid_ids=[]\n",
    "vid_thumb_urls=[]\n",
    "for file in files:\n",
    "\tvideos_loop= pd.read_csv(file)\n",
    "\tvid_ids.append(list(videos_loop[pd.to_datetime(videos_loop[\"upload_date\"])>datetime.datetime(2012,7,1,0,0,0,0)][\"video_id\"]))\n",
    "\tvid_thumb_urls.append(list(videos_loop[pd.to_datetime(videos_loop[\"upload_date\"])>datetime.datetime(2012,7,1,0,0,0,0)][\"thumbnail_url\"]))\n",
    "\t\n",
    "vid_ids=list(itertools.chain(*vid_ids))\n",
    "vid_thumb_urls=list(itertools.chain(*vid_thumb_urls))\n",
    "\n",
    "df = pd.DataFrame(columns=['video_id','thumbnail_url', 'labels','faces','texts','adult','medical','racy','spoof','violence'])\n",
    "ii = 0\n",
    "\n",
    "for i in range(len(vid_ids)):\n",
    "\tif vid_thumb_urls[i] is not NaN:\n",
    "\t\ttime.sleep(5)\n",
    "\t\ttry:\n",
    "\t\t\tdf.loc[len(df)] = main(video_id=vid_ids[i],inputfile=vid_thumb_urls[i])\n",
    "\t\t\tii += 1\n",
    "\n",
    "\t\texcept:\n",
    "\t\t\tpass\n",
    "\t\tif ii % 30 == 0 or i==len(vid_ids)-1 or i==len(vid_ids):\n",
    "\t\t\tdf.to_csv('thumbnail_data_'+str(datetime.datetime.now()).replace('-','').replace(' ','_').replace(':','-')+'.txt', header=True, index=None, mode='w')\n",
    "\t\t\tprint(\"Num videos\",i,\"---- Percent complete:\",(round(i/len(vid_ids),3))*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Google API uses deep learning to identify number of faces, facial expressions and the text contained in the thumbnail image of each youtube video. An example is shown below of the facial recognition. The google vision also accurately identifies any text inside the thunbnail image.\n",
    "\n",
    "![kaggle_img001](https://github.com/jmmerrell/ws/blob/master/data/youtube_jadoinstuff/output_images/thumbnail_zVRQiZCnKPs.jpg?raw=true)\n",
    "\n",
    "I combined the YouTube data with the thumbnail image data for each channel, including nearly 100 videos for each channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "NdiuT2hDxwFR"
   },
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\merre\\\\Desktop\\\\ws\\\\data\\\\youtube_jadoinstuff\")\n",
    "\n",
    "files= [\"shanieology.txt\",\"simau.txt\",\"soundslikepizza.txt\",\"azerrz.txt\",\"BigShade.txt\",\"black_gryph0n.txt\"\n",
    ",\"brian_hull.txt\",\"brizzy_voices.txt\",\"brock_baker.txt\",\"charlie_hopkinson.txt\",\"danny_padilla_&_mason_sperling.txt\"\n",
    ",\"ja_doin_stuff.txt\",\"joshiiwuh.txt\",\"knep.txt\",\"ori.txt\",\"redfireball555.txt\",\"scheiffer_bates.txt\",\"daniel_ferguson.txt\",\n",
    "\"BigShade.txt\",\"best_in_class.txt\",\"maxamili.txt\",\"mikey_bolts.txt\"]\n",
    "\n",
    "df = pd.DataFrame(columns=['video_id','title','title_len','words','upper_pct','emoji_count','upload_date','upload_time',\n",
    "                           'upload_day','upload_time_of_day','viewCount','likeCount','dislikeCount','favoriteCount',\n",
    "                           'commentCount','duration','definition','caption','licensedContent','thumbnail_url', 'thumbnail_w', \n",
    "                           'thumbnail_h', 'tags','num_tags','categoryId','liveBroadcastContent',\n",
    "                           'topicCategories', 'channel', 'channel_subs', 'channel_views', 'channel_videos','desc'])\n",
    "\n",
    "#Loop through all the youtuber's data files and combine into on data frame \n",
    "for file in files:\n",
    "\tdf_add= pd.read_csv(file)\n",
    "\tdf = df.append(df_add.drop(['Unnamed: 0'],axis=1))\n",
    "\n",
    "#Read in the files that have the thumbnail data, and combine with the youtuber data\n",
    "df_thumb = pd.read_csv(\"thumbnail_data_20210801_23-03-21.638854.txt\").append(pd.read_csv(\"thumbnail_data_20210802_21-39-16.451172.txt\"))\n",
    "df_all = pd.merge(df.drop('defaultAudioLanguage',axis=1),df_thumb.drop(['thumbnail_url'],axis=1),on=\"video_id\",how=\"inner\").drop(['emoji_count'],axis=1)\n",
    "df_all['all_text'] = df_all['title'].astype(str) + df_all['tags'].astype(str) + df_all['desc'].astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-R56VsWFkn5e"
   },
   "source": [
    "To get an overview of the data, let's check the first rows and the size of the data set. We can see the data has 1,940 rows and 40 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "spzEVFG4y0TZ",
    "outputId": "bc1805c6-46ba-4b07-dab4-693a6c99f74f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>title_len</th>\n",
       "      <th>words</th>\n",
       "      <th>upper_pct</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>upload_time</th>\n",
       "      <th>upload_day</th>\n",
       "      <th>upload_time_of_day</th>\n",
       "      <th>viewCount</th>\n",
       "      <th>...</th>\n",
       "      <th>desc</th>\n",
       "      <th>labels</th>\n",
       "      <th>faces</th>\n",
       "      <th>texts</th>\n",
       "      <th>adult</th>\n",
       "      <th>medical</th>\n",
       "      <th>racy</th>\n",
       "      <th>spoof</th>\n",
       "      <th>violence</th>\n",
       "      <th>all_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eyyTBJUKI3c</td>\n",
       "      <td>Skeletor reacts to Episode 1 of Teela and the ...</td>\n",
       "      <td>80</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2021-07-25</td>\n",
       "      <td>11:22:54</td>\n",
       "      <td>6</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>15005</td>\n",
       "      <td>...</td>\n",
       "      <td>In this video Skeletor will react and give his...</td>\n",
       "      <td>['Action figure', 'Animated cartoon', 'Animati...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['A', 'AND', 'BAIT', 'R.I.P.', 'SWITCH!', 'THI...</td>\n",
       "      <td>UNLIKELY</td>\n",
       "      <td>UNLIKELY</td>\n",
       "      <td>UNLIKELY</td>\n",
       "      <td>LIKELY</td>\n",
       "      <td>UNLIKELY</td>\n",
       "      <td>Skeletor reacts to Episode 1 of Teela and the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1Bmx8Dti6Y</td>\n",
       "      <td>Top 5 Worst Reboot Offences Part 2 || Skeletor...</td>\n",
       "      <td>53</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2021-07-27</td>\n",
       "      <td>18:40:21</td>\n",
       "      <td>1</td>\n",
       "      <td>night</td>\n",
       "      <td>9497</td>\n",
       "      <td>...</td>\n",
       "      <td>In this video Skeletor finishes his top 5 wors...</td>\n",
       "      <td>['Animated cartoon', 'Animation', 'Art', 'Ente...</td>\n",
       "      <td>['other', 'other', 'other', 'other', 'other']</td>\n",
       "      <td>['Stop', 'Stop exploiting\\nour nostalgia!\\n', ...</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "      <td>UNLIKELY</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "      <td>LIKELY</td>\n",
       "      <td>UNLIKELY</td>\n",
       "      <td>Top 5 Worst Reboot Offences Part 2 || Skeletor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DStvv0peyYQ</td>\n",
       "      <td>Top 5 Worst Reboot Offences Part 1 :Skeletor R...</td>\n",
       "      <td>51</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2021-07-21</td>\n",
       "      <td>11:03:11</td>\n",
       "      <td>2</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>5312</td>\n",
       "      <td>...</td>\n",
       "      <td>In this video Skeletor does a top 5 list of re...</td>\n",
       "      <td>['Advertising', 'Animated cartoon', 'Animation...</td>\n",
       "      <td>['other', 'other', 'other', 'other']</td>\n",
       "      <td>['1', '5', 'Hollywood', 'I', \"I wonder why we ...</td>\n",
       "      <td>UNLIKELY</td>\n",
       "      <td>UNLIKELY</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "      <td>LIKELY</td>\n",
       "      <td>UNLIKELY</td>\n",
       "      <td>Top 5 Worst Reboot Offences Part 1 :Skeletor R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PCwtNUQ3t30</td>\n",
       "      <td>Skeletor Reacts to the new MOTU toy line Pt2 W...</td>\n",
       "      <td>71</td>\n",
       "      <td>15</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>2021-07-17</td>\n",
       "      <td>13:34:25</td>\n",
       "      <td>5</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>5079</td>\n",
       "      <td>...</td>\n",
       "      <td>This video is part 2 of Skeletor's reaction to...</td>\n",
       "      <td>['Animated cartoon', 'Animation', 'Art', 'Cart...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['ETERNIA', 'No', 'SHORE', 'So...', \"So...\\nWh...</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "      <td>LIKELY</td>\n",
       "      <td>UNLIKELY</td>\n",
       "      <td>Skeletor Reacts to the new MOTU toy line Pt2 W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yiQto5PfuII</td>\n",
       "      <td>Skeletor Reacts to Episode 2 of Teela and the ...</td>\n",
       "      <td>87</td>\n",
       "      <td>16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2021-07-31</td>\n",
       "      <td>12:13:54</td>\n",
       "      <td>5</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>4891</td>\n",
       "      <td>...</td>\n",
       "      <td>This video is part one of Skeletor watches and...</td>\n",
       "      <td>['Animated cartoon', 'Animation', 'Art', 'Elec...</td>\n",
       "      <td>['other']</td>\n",
       "      <td>['SOMETHING', 'SOMETHING\\nSTINKS!\\n', 'STINKS!']</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "      <td>POSSIBLE</td>\n",
       "      <td>UNLIKELY</td>\n",
       "      <td>Skeletor Reacts to Episode 2 of Teela and the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>mCjhGzx3FOA</td>\n",
       "      <td>Impressions of Famous Authors</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2019-07-22</td>\n",
       "      <td>13:53:24</td>\n",
       "      <td>0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>51825</td>\n",
       "      <td>...</td>\n",
       "      <td>Go to http://www.audible.com/MIKEYBOLTS or tex...</td>\n",
       "      <td>['Audio equipment', 'Baseball cap', 'Beard', '...</td>\n",
       "      <td>['other']</td>\n",
       "      <td>['AUTHORS', 'FAMOUS', 'FAMOUS\\nAUTHORS\\n']</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "      <td>POSSIBLE</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "      <td>Impressions of Famous Authors['Impressions', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>aTm4yI1hbrU</td>\n",
       "      <td>14 Things That Drive Me Nuts In 2020</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-08-25</td>\n",
       "      <td>15:02:31</td>\n",
       "      <td>1</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>41215</td>\n",
       "      <td>...</td>\n",
       "      <td>MAN ITS GOOD TO BE BACK! :) \\nThanks for watch...</td>\n",
       "      <td>['Audio equipment', 'Azure', 'Baseball cap', '...</td>\n",
       "      <td>['happy']</td>\n",
       "      <td>['2020', '2020\\n']</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "      <td>14 Things That Drive Me Nuts In 2020['Impressi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>W8cR5YsSo-I</td>\n",
       "      <td>THE QUARANTINE ANTHEM</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>18:52:07</td>\n",
       "      <td>4</td>\n",
       "      <td>night</td>\n",
       "      <td>40042</td>\n",
       "      <td>...</td>\n",
       "      <td>A song I made about quarantine.\\nPls Subscribe...</td>\n",
       "      <td>['Advertising', 'Brand', 'Cameras &amp; optics', '...</td>\n",
       "      <td>['other']</td>\n",
       "      <td>['MUSIC', 'MUSIC VIDEO\\n', 'VIDEO']</td>\n",
       "      <td>UNLIKELY</td>\n",
       "      <td>UNLIKELY</td>\n",
       "      <td>UNLIKELY</td>\n",
       "      <td>VERY_LIKELY</td>\n",
       "      <td>UNLIKELY</td>\n",
       "      <td>THE QUARANTINE ANTHEM['corona virus', 'corona ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>DmBZ1vjOibM</td>\n",
       "      <td>IMPRESSIONS CHALLENGE 16 | Mikey Bolts</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>2021-04-14</td>\n",
       "      <td>15:06:16</td>\n",
       "      <td>2</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>33362</td>\n",
       "      <td>...</td>\n",
       "      <td>- Hello Fellas &amp; Stella's, Friends, and Marshe...</td>\n",
       "      <td>['Animated cartoon', 'Audio equipment', 'Baseb...</td>\n",
       "      <td>['happy', 'happy']</td>\n",
       "      <td>['00', '00\\nIMPRESSIONS\\nCHALLENGE\\n16\\n', '16...</td>\n",
       "      <td>UNLIKELY</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "      <td>IMPRESSIONS CHALLENGE 16 | Mikey Bolts['corona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>Tyz2Pcp1p5A</td>\n",
       "      <td>HOTDOG IN A RAINCOAT - Original Animation</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2021-02-22</td>\n",
       "      <td>14:54:14</td>\n",
       "      <td>0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>16722</td>\n",
       "      <td>...</td>\n",
       "      <td>hello friends. here's something i made. hope y...</td>\n",
       "      <td>['Animated cartoon', 'Art', 'Brand', 'Cartoon'...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['@mikeybolts', 'A', 'A\\nDOG\\n@mikeybolts\\n', ...</td>\n",
       "      <td>UNLIKELY</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "      <td>VERY_UNLIKELY</td>\n",
       "      <td>POSSIBLE</td>\n",
       "      <td>UNLIKELY</td>\n",
       "      <td>HOTDOG IN A RAINCOAT - Original Animation['cor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1940 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id                                              title  \\\n",
       "0     eyyTBJUKI3c  Skeletor reacts to Episode 1 of Teela and the ...   \n",
       "1     S1Bmx8Dti6Y  Top 5 Worst Reboot Offences Part 2 || Skeletor...   \n",
       "2     DStvv0peyYQ  Top 5 Worst Reboot Offences Part 1 :Skeletor R...   \n",
       "3     PCwtNUQ3t30  Skeletor Reacts to the new MOTU toy line Pt2 W...   \n",
       "4     yiQto5PfuII  Skeletor Reacts to Episode 2 of Teela and the ...   \n",
       "...           ...                                                ...   \n",
       "1935  mCjhGzx3FOA                      Impressions of Famous Authors   \n",
       "1936  aTm4yI1hbrU               14 Things That Drive Me Nuts In 2020   \n",
       "1937  W8cR5YsSo-I                              THE QUARANTINE ANTHEM   \n",
       "1938  DmBZ1vjOibM             IMPRESSIONS CHALLENGE 16 | Mikey Bolts   \n",
       "1939  Tyz2Pcp1p5A          HOTDOG IN A RAINCOAT - Original Animation   \n",
       "\n",
       "     title_len words  upper_pct upload_date upload_time upload_day  \\\n",
       "0           80    14   0.000000  2021-07-25    11:22:54          6   \n",
       "1           53     9   0.000000  2021-07-27    18:40:21          1   \n",
       "2           51     9   0.000000  2021-07-21    11:03:11          2   \n",
       "3           71    15   0.066667  2021-07-17    13:34:25          5   \n",
       "4           87    16   0.000000  2021-07-31    12:13:54          5   \n",
       "...        ...   ...        ...         ...         ...        ...   \n",
       "1935        29     4   0.000000  2019-07-22    13:53:24          0   \n",
       "1936        36     8   0.000000  2020-08-25    15:02:31          1   \n",
       "1937        21     3   1.000000  2020-03-27    18:52:07          4   \n",
       "1938        38     5   0.400000  2021-04-14    15:06:16          2   \n",
       "1939        41     6   0.666667  2021-02-22    14:54:14          0   \n",
       "\n",
       "     upload_time_of_day viewCount  ...  \\\n",
       "0             afternoon     15005  ...   \n",
       "1                 night      9497  ...   \n",
       "2             afternoon      5312  ...   \n",
       "3             afternoon      5079  ...   \n",
       "4             afternoon      4891  ...   \n",
       "...                 ...       ...  ...   \n",
       "1935          afternoon     51825  ...   \n",
       "1936          afternoon     41215  ...   \n",
       "1937              night     40042  ...   \n",
       "1938          afternoon     33362  ...   \n",
       "1939          afternoon     16722  ...   \n",
       "\n",
       "                                                   desc  \\\n",
       "0     In this video Skeletor will react and give his...   \n",
       "1     In this video Skeletor finishes his top 5 wors...   \n",
       "2     In this video Skeletor does a top 5 list of re...   \n",
       "3     This video is part 2 of Skeletor's reaction to...   \n",
       "4     This video is part one of Skeletor watches and...   \n",
       "...                                                 ...   \n",
       "1935  Go to http://www.audible.com/MIKEYBOLTS or tex...   \n",
       "1936  MAN ITS GOOD TO BE BACK! :) \\nThanks for watch...   \n",
       "1937  A song I made about quarantine.\\nPls Subscribe...   \n",
       "1938  - Hello Fellas & Stella's, Friends, and Marshe...   \n",
       "1939  hello friends. here's something i made. hope y...   \n",
       "\n",
       "                                                 labels  \\\n",
       "0     ['Action figure', 'Animated cartoon', 'Animati...   \n",
       "1     ['Animated cartoon', 'Animation', 'Art', 'Ente...   \n",
       "2     ['Advertising', 'Animated cartoon', 'Animation...   \n",
       "3     ['Animated cartoon', 'Animation', 'Art', 'Cart...   \n",
       "4     ['Animated cartoon', 'Animation', 'Art', 'Elec...   \n",
       "...                                                 ...   \n",
       "1935  ['Audio equipment', 'Baseball cap', 'Beard', '...   \n",
       "1936  ['Audio equipment', 'Azure', 'Baseball cap', '...   \n",
       "1937  ['Advertising', 'Brand', 'Cameras & optics', '...   \n",
       "1938  ['Animated cartoon', 'Audio equipment', 'Baseb...   \n",
       "1939  ['Animated cartoon', 'Art', 'Brand', 'Cartoon'...   \n",
       "\n",
       "                                              faces  \\\n",
       "0                                                []   \n",
       "1     ['other', 'other', 'other', 'other', 'other']   \n",
       "2              ['other', 'other', 'other', 'other']   \n",
       "3                                                []   \n",
       "4                                         ['other']   \n",
       "...                                             ...   \n",
       "1935                                      ['other']   \n",
       "1936                                      ['happy']   \n",
       "1937                                      ['other']   \n",
       "1938                             ['happy', 'happy']   \n",
       "1939                                             []   \n",
       "\n",
       "                                                  texts          adult  \\\n",
       "0     ['A', 'AND', 'BAIT', 'R.I.P.', 'SWITCH!', 'THI...       UNLIKELY   \n",
       "1     ['Stop', 'Stop exploiting\\nour nostalgia!\\n', ...  VERY_UNLIKELY   \n",
       "2     ['1', '5', 'Hollywood', 'I', \"I wonder why we ...       UNLIKELY   \n",
       "3     ['ETERNIA', 'No', 'SHORE', 'So...', \"So...\\nWh...  VERY_UNLIKELY   \n",
       "4      ['SOMETHING', 'SOMETHING\\nSTINKS!\\n', 'STINKS!']  VERY_UNLIKELY   \n",
       "...                                                 ...            ...   \n",
       "1935         ['AUTHORS', 'FAMOUS', 'FAMOUS\\nAUTHORS\\n']  VERY_UNLIKELY   \n",
       "1936                                 ['2020', '2020\\n']  VERY_UNLIKELY   \n",
       "1937                ['MUSIC', 'MUSIC VIDEO\\n', 'VIDEO']       UNLIKELY   \n",
       "1938  ['00', '00\\nIMPRESSIONS\\nCHALLENGE\\n16\\n', '16...       UNLIKELY   \n",
       "1939  ['@mikeybolts', 'A', 'A\\nDOG\\n@mikeybolts\\n', ...       UNLIKELY   \n",
       "\n",
       "            medical           racy          spoof       violence  \\\n",
       "0          UNLIKELY       UNLIKELY         LIKELY       UNLIKELY   \n",
       "1          UNLIKELY  VERY_UNLIKELY         LIKELY       UNLIKELY   \n",
       "2          UNLIKELY  VERY_UNLIKELY         LIKELY       UNLIKELY   \n",
       "3     VERY_UNLIKELY  VERY_UNLIKELY         LIKELY       UNLIKELY   \n",
       "4     VERY_UNLIKELY  VERY_UNLIKELY       POSSIBLE       UNLIKELY   \n",
       "...             ...            ...            ...            ...   \n",
       "1935  VERY_UNLIKELY  VERY_UNLIKELY       POSSIBLE  VERY_UNLIKELY   \n",
       "1936  VERY_UNLIKELY  VERY_UNLIKELY  VERY_UNLIKELY  VERY_UNLIKELY   \n",
       "1937       UNLIKELY       UNLIKELY    VERY_LIKELY       UNLIKELY   \n",
       "1938  VERY_UNLIKELY  VERY_UNLIKELY  VERY_UNLIKELY  VERY_UNLIKELY   \n",
       "1939  VERY_UNLIKELY  VERY_UNLIKELY       POSSIBLE       UNLIKELY   \n",
       "\n",
       "                                               all_text  \n",
       "0     Skeletor reacts to Episode 1 of Teela and the ...  \n",
       "1     Top 5 Worst Reboot Offences Part 2 || Skeletor...  \n",
       "2     Top 5 Worst Reboot Offences Part 1 :Skeletor R...  \n",
       "3     Skeletor Reacts to the new MOTU toy line Pt2 W...  \n",
       "4     Skeletor Reacts to Episode 2 of Teela and the ...  \n",
       "...                                                 ...  \n",
       "1935  Impressions of Famous Authors['Impressions', '...  \n",
       "1936  14 Things That Drive Me Nuts In 2020['Impressi...  \n",
       "1937  THE QUARANTINE ANTHEM['corona virus', 'corona ...  \n",
       "1938  IMPRESSIONS CHALLENGE 16 | Mikey Bolts['corona...  \n",
       "1939  HOTDOG IN A RAINCOAT - Original Animation['cor...  \n",
       "\n",
       "[1940 rows x 40 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2fnRvnxblxf3"
   },
   "source": [
    "There are 1940 YouTube videos for the analysis and 40 features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lA-G5X08wMQG"
   },
   "source": [
    "## 3. Analyze and prepare the data\n",
    "\n",
    "In the next steps we will create new fields that could potentially be valuable, handle missing values, and determine if any columns should be left out of the study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdAZIHMp5XAA"
   },
   "source": [
    "### 4.1. Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SSuk5CEtySnK",
    "outputId": "d6b82c27-0a1c-4d73-bd41-88b1782434d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PoolQC          1453\n",
      "MiscFeature     1406\n",
      "Alley           1369\n",
      "Fence           1179\n",
      "FireplaceQu      690\n",
      "LotFrontage      259\n",
      "GarageYrBlt       81\n",
      "GarageType        81\n",
      "GarageFinish      81\n",
      "GarageQual        81\n",
      "GarageCond        81\n",
      "BsmtFinType2      38\n",
      "BsmtExposure      38\n",
      "BsmtFinType1      37\n",
      "BsmtCond          37\n",
      "BsmtQual          37\n",
      "MasVnrArea         8\n",
      "MasVnrType         8\n",
      "Electrical         1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "##See if any columns have a lot of missing data\n",
    "print(df_all.isna().mean().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g6EW6A6X1VWU"
   },
   "source": [
    "Some features have missing values counting for the majority of their entries. Checking the [competition page](https://www.kaggle.com/c/home-data-for-ml-course/data), we find more details about the values for each feature, which will help us handle missing data.\n",
    "\n",
    "For instance, in the columns `PoolQC`, `MiscFeature`, `Alley`, `Fence`, and `FireplaceQu`, the missing values mean that the house doesn't count with that specific feature, so, we'll fill the missing values with \"NA\". All the null values in columns starting with `Garage` and `Bsmt` are related to houses that don't have a garage or basement, respectively. We'll fill those and the remaining null values with \"NA\" or the mean value, considering if the features are categorical or numerical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2UZ-muYNrY3-"
   },
   "source": [
    "### 4.2. Preprocessing the categorical variables\n",
    "\n",
    "Most machine learning models only work with numerical variables. Therefore, if we feed the model with categorical variables without preprocessing them first, we'll get an error.\n",
    "\n",
    "There are several ways to deal with categorical values. Here, we'll use *One-Hot Encoding*, which will create new columns indicating the presence or absence of each value in the original data.\n",
    "\n",
    "One issue of One-Hot Encoding is dealing with variables with numerous unique categories since it will create a new column for each unique category. Thus, this project will only include categorical variables with no more than 15 unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6xPK6s8cuux7"
   },
   "outputs": [],
   "source": [
    "# Select categorical columns with no more than 15 unique values\n",
    "categorical_cols = [col for col in X_train_full.columns if \n",
    "                   X_train_full[col].nunique() <= 15 and\n",
    "                   X_train_full[col].dtype == 'object']\n",
    "\n",
    "# Select numeric values\n",
    "numeric_cols = [col for col in X_train_full.columns if\n",
    "                X_train_full[col].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Keep selected columns\n",
    "my_columns = categorical_cols + numeric_cols\n",
    "X_train = X_train_full[my_columns].copy()\n",
    "X_valid = X_valid_full[my_columns].copy()\n",
    "X_test = X_test_full[my_columns].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01zQqWGDxQni"
   },
   "source": [
    "### 4.3. Create a pipeline\n",
    "\n",
    "*Pipelines* are a great way to keep the data modeling and preprocessing more organized and easier to understand. Creating a pipeline, we'll handle the missing values and the preprocessing covered in the previous two steps. \n",
    "\n",
    "As defined above, numerical missing entries will be filled with the mean value while missing categorical variables will be filled with \"NA\". Furthermore, categorical columns will also be preprocessed with One-Hot Encoding.\n",
    "\n",
    "We are using *SimpleImputer* to fill in missing values and *ColumnTransformer* will help us to apply the numerical and categorical preprocessors in a single transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "l19Cpkn-yi7S"
   },
   "outputs": [],
   "source": [
    "# Preprocessing numerical values\n",
    "numerical_transformer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Preprocessing categorical values\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "                                   ('imputer', SimpleImputer(strategy='constant', fill_value='NA')),\n",
    "                                   ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "                                   ])\n",
    "\n",
    "# Pack the preprocessors together\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "                                 ('num', numerical_transformer, numeric_cols),\n",
    "                                 ('cat', categorical_transformer, categorical_cols)\n",
    "                                 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unxjL-XN1lr_"
   },
   "source": [
    "## 5. Define a model\n",
    "\n",
    "Now that we have bundled our preprocessors in a pipeline, we can define a model. In this article, we are working with **XGBoost**, one of the most effective machine learning algorithms, that presents great results in many Kaggle competitions. As a metric of evaluation, we are using the **Mean Absolute Error**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TqAjAZTa1TCB",
    "outputId": "9e7b728e-a59c-49e7-d140-7fc12adeef66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 16706.181988441782\n"
     ]
    }
   ],
   "source": [
    "# Define the model with default parameters\n",
    "model = XGBRegressor(verbosity=0, random_state=0)\n",
    "\n",
    "# Pack preprocessing and modeling together in a pipeline\n",
    "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('model', model)\n",
    "                              ])\n",
    "\n",
    "# Preprocessing of training data, fit model \n",
    "my_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "preds = my_pipeline.predict(X_valid)\n",
    "\n",
    "print('MAE:', mean_absolute_error(y_valid, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training and validation data\n",
    "\n",
    "It is crucial to break our data into a set for training the model and another one to validate the results. It's worth mentioning that we should never use the test data here. Our test set stays untouched until we are satisfied with our model's performance.\n",
    "\n",
    "What we're going to do is taking the predictors **X** and target vector **y** and breaking them into training and validation sets. For that, we'll use scikit-learn's `train_test_split`.\n",
    "\n",
    "print(f'Shape of X_train_full: {X_train_full.shape}')\n",
    "print(f'Shape of X_valid_full: {X_valid_full.shape}')\n",
    "print(f'Shape of y_train: {y_train.shape}')\n",
    "print(f'Shape of y_valid: {y_valid.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BMBNT7Er4qzJ"
   },
   "source": [
    "## 6. Cross-validation\n",
    "\n",
    "Using [Cross-Validation](https://scikit-learn.org/stable/modules/cross_validation.html#) can yield better results. Instead of simply using the training and test sets, cross-validation will run our model on different subsets of the data to get multiple measures of model quality.\n",
    "\n",
    "We'll use the cross-validator [KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) in its default setup to split the training data into 5 folds. Then, each fold will be used once as validation while the remaining folds will form the training set. After that, [cross-validate](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html) will evaluate the metrics. In this case, we're using the Mean Absolute Error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tto1hz7_1Y9_",
    "outputId": "60b811b2-ceef-4705-e093-0fb05e12b85e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MAE score: 16168.894833206665\n"
     ]
    }
   ],
   "source": [
    "# Using KFold cross-validator\n",
    "kfold = KFold(shuffle=True, random_state=0)\n",
    "\n",
    "# Evaluating the Mean Absolute Error\n",
    "scores = cross_validate(my_pipeline, X_train, y_train, \n",
    "                              scoring='neg_mean_absolute_error', cv=kfold)\n",
    "\n",
    "# Multiply by -1 since sklearn calculates negative MAE\n",
    "print('Average MAE score:', (scores['test_score'] * -1).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gvnb0Y_15qBm"
   },
   "source": [
    "With cross-validation we could improve our score, reducing the error. In the next step, we'll try to further improve the model, optimizing some hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FuD8SXiu6J_X"
   },
   "source": [
    "## 7. Hyperparameter tuning\n",
    "\n",
    "**XGBoost** in its default setup usually yields great results, but it also has plenty of hyperparameters that can be optimized to improve the model. Here, we'll use a method called [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) which will search over specified parameter values and return the best ones. Once again, we'll utilize the pipeline and the cross-validator *KFold* defined above.\n",
    "\n",
    "*GridSearchCV* will perform an exhaustive search over parameters, which can demand a lot of computational power and take a lot of time to be finished. We can speed up the process a little bit by setting the parameter `n_jobs` to `-1`, which means that the machine will use all processors on the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "9VTTGyQ98Bdx"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To pass parameter in a pipeline, we should add the names of the steps and the parameter name separated by a ‘__’.\n",
    "Ex: Instead of 'n_estimators', we should set 'model__n_estimators'.\n",
    "https://github.com/scikit-learn/scikit-learn/issues/18472\n",
    "\"\"\"\n",
    "# parameters to be searched over\n",
    "param_grid = {'model__n_estimators': [10, 50, 100, 200, 400, 600],\n",
    "              'model__max_depth': [2, 3, 5, 7, 10],\n",
    "              'model__min_child_weight': [0.0001, 0.001, 0.01],\n",
    "              'model__learning_rate': [0.01, 0.1, 0.5, 1]}\n",
    "\n",
    "# find the best parameter\n",
    "kfold = KFold(shuffle=True, random_state=0)\n",
    "grid_search = GridSearchCV(my_pipeline, param_grid, scoring='neg_mean_absolute_error', cv=kfold, n_jobs=-1)\n",
    "grid_result = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9nQZUcYr4sog",
    "outputId": "956ee39a-647d-43de-eb55-26ef8ca7bb6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best result: 15750.17 for {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__min_child_weight': 0.0001, 'model__n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "print('Best result:', round((grid_result.best_score_ * -1), 2), 'for', grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_XBFlq4mNazW"
   },
   "source": [
    "## 8. Generate test predictions\n",
    "\n",
    "After tuning some hyperparameters, it's time to go over the modeling process again to make predictions on the test set. We'll define our final model based on the optimized values provided by *GridSearchCV*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "AHLH9rTFy4QI"
   },
   "outputs": [],
   "source": [
    "# Define final model\n",
    "final_model = XGBRegressor(n_estimators=400, \n",
    "                           max_depth=3, \n",
    "                           min_child_weight=0.0001, \n",
    "                           learning_rate=0.1, \n",
    "                           verbosity=0, \n",
    "                           random_state=0\n",
    "                           )\n",
    "\n",
    "# Create a pipeline\n",
    "final_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                 ('final_model', final_model)\n",
    "                                 ])\n",
    "\n",
    "# Fit the model\n",
    "final_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions on the test set\n",
    "final_prediction = final_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6g2V9FoM_H7"
   },
   "source": [
    "## 9. Submit your results\n",
    "\n",
    "We're almost there! The machine learning modeling is done, but we still need to submit our results to have our score recorded.\n",
    "\n",
    "This step is quite simple. We need to create a `.csv` file containing the predictions. This file consists of a DataFrame with two columns. In this case, one column for \"Id\" and the other one for the test predictions on the target feature. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "8xmm96G7QTc5"
   },
   "outputs": [],
   "source": [
    "# Save test predictions to .csv file\n",
    "output = pd.DataFrame({'Id': X_test.index,\n",
    "                       'SalePrice': final_prediction})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NAVOrwBEQ_-h"
   },
   "source": [
    "## 10. Join the competition\n",
    "\n",
    "Finally, we just need to join the competition. Please follow the steps below, according to Kaggle's instructions. \n",
    "\n",
    "*   Start by accessing the [competition page](https://www.kaggle.com/c/home-data-for-ml-course) and clicking on **Join Competition**.\n",
    "*   In your Kaggle notebook, click on the blue Save Version button in the top right corner of the window.\n",
    "*   A pop-up window will show up. Select the option **Save and Run All** and then click on the blue Save button.\n",
    "*   A new pop-up shows up in the bottom left corner while your notebook is running. When it stops running, click on the number to the right of the **Save Version** button. You should click on the **ellipsis (...)** to the right of the most recent notebook version, and select **Open in Viewer**. This brings you into view mode of the same page.\n",
    "*   Now, click on the **Output** tab on the right of the screen. Then, click on the blue **Submit** button to submit your results to the leaderboard.\n",
    "\n",
    "After submitting, you can check your score and position on the [leaderboard](https://www.kaggle.com/c/home-data-for-ml-course/leaderboard).\n",
    "\n",
    "![kaggle_img004](https://github.com/rmpbastos/data_science/blob/master/img/kaggle_img4.jpg?raw=true)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGF0qoH-YFgo"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "This article was intended to be instructive, helping data science beginners to structure their first projects on Kaggle in simple steps. With this straightforward approach, I've got a score of **14,778.87**, which ranked this project in the Top 7%.\n",
    "\n",
    "After further studying, you can go back on past projects and try to enhance their performance, using new skills you've learned. To improve this project, we could investigate and treat the outliers more closely, apply a different approach to missing values, or do some feature engineering, for instance.\n",
    "\n",
    "My advice to beginners is to keep it simple when starting out. Instead of aiming at the \"perfect\" model, focus on completing the project, applying your skills correctly, and learning from your mistakes, understanding where and why you messed things up. The data science community is on constant expansion and there's plenty of more experienced folks willing to help on websites like Kaggle or Stack Overflow. Try to learn from their past mistakes as well! With practice and discipline, it's just a matter of time to start building more elaborate projects and climb up the ranking of Kaggle's competitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wmzWu8_1YD-_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN2vviYKmlbPVp76dYgrjBM",
   "collapsed_sections": [
    "2Ime_gOak4Fe"
   ],
   "include_colab_link": true,
   "name": "Housing_Prices_Competition.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
